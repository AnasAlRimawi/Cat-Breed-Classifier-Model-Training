{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, GlobalMaxPooling2D, AveragePooling2D, GlobalAveragePooling2D,Dropout\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224,224)\n",
    "IMG_SHAPE_GN = (224,224,3)\n",
    "steps_per_epoch = 55 #if you get warning message while fitting after changing this variable change it back to 60  samplesize//batch_size\n",
    "batch_size = 32 #if you get warning message after changing this variable change it back to 32\n",
    "validation_steps = 18 #if you get warning message after changing this variable change it back to 15  samplesize//batch_size\n",
    "epochs = 10\n",
    "df = pd.read_csv(\"Cats.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image (input) for the model\n",
    "def process(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = tf.keras.applications.mobilenet.preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Read image\n",
    "def get_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    validation_split=0.25,\n",
    "                                    rotation_range=90,\n",
    "                                    width_shift_range=0.2, \n",
    "                                    height_shift_range=0.2\n",
    "                                  )\n",
    "validation_datagen = ImageDataGenerator(\n",
    "                                    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "                                    validation_split=0.25,\n",
    "    )\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory='images/',\n",
    "        x_col='image',\n",
    "        y_col='classname',\n",
    "        target_size=IMG_SHAPE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        seed=420,\n",
    "        subset='training'\n",
    ")\n",
    "valid_gen_flow = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory='images/',\n",
    "        x_col='image',\n",
    "        y_col='classname',\n",
    "        target_size=IMG_SHAPE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        #seed=500,\n",
    "        shuffle=False,\n",
    "        subset='validation')\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test,\n",
    "        directory='test/test',\n",
    "        x_col='image',\n",
    "        y_col='classname',\n",
    "        target_size=IMG_SHAPE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating & Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainedModel = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=IMG_SHAPE_GN,\n",
    "     include_top=False,\n",
    "     weights='imagenet',\n",
    "     pooling='avg'\n",
    ")\n",
    "pretrainedModel.trainable = False\n",
    "\n",
    "inputs = pretrainedModel.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrainedModel.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(12, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen_flow,\n",
    "    validation_data=valid_gen_flow,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1, \n",
    "    epochs=epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_gen, verbose = 0)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=valid_gen_flow.class_indices, yticklabels=valid_gen_flow.class_indices)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = model.evaluate(test_gen, verbose = 0)\n",
    "print(f\"The accuarcy for this model is {accuracy:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = get_image(\"test1.jpg\")\n",
    "img2 = process(img1)\n",
    "classes = np.array(list(train_gen_flow.class_indices))\n",
    "y_pred = classes[np.argmax(model.predict(img2, verbose = 0), axis=1)]\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(img1)\n",
    "plt.title(y_pred[0])\n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"meow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
